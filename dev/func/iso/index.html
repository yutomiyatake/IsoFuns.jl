<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Isotonic regression · IsoFuns.jl</title><meta name="title" content="Isotonic regression · IsoFuns.jl"/><meta property="og:title" content="Isotonic regression · IsoFuns.jl"/><meta property="twitter:title" content="Isotonic regression · IsoFuns.jl"/><meta name="description" content="Documentation for IsoFuns.jl."/><meta property="og:description" content="Documentation for IsoFuns.jl."/><meta property="twitter:description" content="Documentation for IsoFuns.jl."/><meta property="og:url" content="https://yutomiyatake.github.io/IsoFuns.jl/func/iso/"/><meta property="twitter:url" content="https://yutomiyatake.github.io/IsoFuns.jl/func/iso/"/><link rel="canonical" href="https://yutomiyatake.github.io/IsoFuns.jl/func/iso/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">IsoFuns.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Functions</span><ul><li class="is-active"><a class="tocitem" href>Isotonic regression</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Generalized-isotonic-regression"><span>Generalized isotonic regression</span></a></li></ul></li><li><a class="tocitem" href="../neariso/">Nearly isotonic regression</a></li></ul></li><li><a class="tocitem" href="../../examples/">Examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Functions</a></li><li class="is-active"><a href>Isotonic regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Isotonic regression</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/main/docs/src/func/iso.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Isotonic-regression"><a class="docs-heading-anchor" href="#Isotonic-regression">Isotonic regression</a><a id="Isotonic-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Isotonic-regression" title="Permalink"></a></h1><p>Suppose that we have <span>$n$</span> independent normal observations <span>$X_i \sim \mathrm{N}(\mu_i,1)$</span> for <span>$i=1,\dots,n$</span>, where</p><p class="math-container">\[\mu_1\leq \mu_2 \leq \dots \leq \mu_n\]</p><p>is a monotone sequence of means of a normal distribution. The maximum likelihood estimate (MLE) of <span>$\mu$</span> is the solution to the constrained optimization problem:</p><p class="math-container">\[\hat{\mu} = \argmax_{\mu_1\leq \dots \leq \mu_n} \sum_{i=1}^n\log p(x_i\mid \mu_i) = \argmin_{\mu_1\leq \dots \leq \mu_n} \sum_{i=1}^n \frac{1}{2} (x_i-\mu_i)^2.\]</p><p>This formulation is  the <strong>isotonic regression</strong> of <span>$x_1,\dots,x_n$</span> with uniform weights (<span>$w_i=1$</span> in the formulation below).</p><p>The weighted formulation reads</p><p class="math-container">\[\hat{\mu} = \argmin_{\mu_1\leq \dots \leq \mu_n} \sum_{i=1}^n \frac{1}{2} w_i (x_i-\mu_i)^2,\]</p><p>where <span>$w_i &gt; 0$</span> <span>$(i=1,\dots,n)$</span>.</p><p>The function <code>iso</code> or <code>iso!</code> solves these problems using the algorithm called PAVA (Pool-Adjacent-Violators algorithm).</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso" href="#IsoFuns.iso"><code>IsoFuns.iso</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso(x::Vector) -&gt; y</code></pre><p>Same as <code>iso!</code> with <code>w=Nothing</code>, but allocates an output vector <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L72-L76">source</a></section><section><div><pre><code class="language-julia hljs">iso(x::Vector, w::Vector) -&gt; y</code></pre><p>Same as <code>iso!</code>, but allocates an output vector <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L79-L83">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso!" href="#IsoFuns.iso!"><code>IsoFuns.iso!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso!(x::Vector, w::Union{Vector, Nothing}=nothing) -&gt; x</code></pre><p>Perform isotonic regression </p><p><strong>Arguments</strong></p><ul><li><code>x</code>: input vector </li><li><code>w</code>: weights, default to ones if not provided</li></ul><p><strong>Outputs</strong></p><ul><li><code>x</code>: output vector, which is monotone</li></ul><p><strong>Algorithm</strong></p><ul><li>PAVA (Pool-Adjacent-Violators algorithm)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L3-L17">source</a></section></article><h1 id="Generalized-isotonic-regression"><a class="docs-heading-anchor" href="#Generalized-isotonic-regression">Generalized isotonic regression</a><a id="Generalized-isotonic-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Generalized-isotonic-regression" title="Permalink"></a></h1><p>The above formulation can be generalized to accommodate distributions other than the normal distribution with a uniform variance. Such a formulation is often called the <strong>generalized isotonic regression</strong>.</p><p>When <span>$X_i\sim p_i(x_i\mid \theta_i)$</span> for <span>$i=1,\dots,n$</span>, where <span>$p_i(x_i\mid\theta_i )$</span> is a one parameter exponential family defined by</p><p class="math-container">\[p_i(x_i\mid \theta_i) = h_i(x_i) \exp (\theta_i x_i -w_i \psi(\theta_i)),\]</p><p>the problem </p><p class="math-container">\[\hat{\theta} = \argmax_{\theta_1\leq \dots \leq \theta_n} \sum_{i=1}^n\log p_i(x_i\mid \theta_i)\]</p><p>can also be solved by the function <code>iso</code> or <code>iso!</code>, as the formulation is equivalent to</p><p class="math-container">\[\hat{\eta} = \argmin_{\eta_1\leq \dots \leq \eta_n} \sum_{i=1}^n \frac{w_i}{2} (x_i-\eta_i)^2 \quad \text{with} \quad \eta = \mathrm{E}_\theta [x] = \psi ^\prime (\theta).\]</p><p>&lt;!– See <a href="#generalized-isotonic-regression">Generalized isotonic regression</a> for the relation between the natural parameter <span>$\theta_i$</span> and the expectation parameter <span>$\eta_i = \mathrm{E}_\theta [x_i] = \psi ^\prime (\theta_i)$</span>. –&gt;</p><p>Below, we list four examples of one parameter exponential families. For each case, the relation between the natural parameter <span>$\theta_i$</span> and the expectation parameter <span>$\eta_i = \mathrm{E}_\theta [x_i] = \psi ^\prime (\theta_i)$</span> is specified. </p><hr/><h3 id="Normal"><a class="docs-heading-anchor" href="#Normal">Normal</a><a id="Normal-1"></a><a class="docs-heading-anchor-permalink" href="#Normal" title="Permalink"></a></h3><p>The probability distribution function (PDF) of the <strong>Normal Distribution</strong> with mean <span>$\mu_i$</span> and standard deviation <span>$\sigma_i\geq 0$</span> is given by</p><p class="math-container">\[p_i(x_i\mid \mu_i) = \frac{1}{\sqrt{2\pi\sigma_i^2}} \exp \bigg( -\frac{(x_i-\mu_i)^2}{2\sigma_i^2} \bigg).\]</p><p>Since</p><p class="math-container">\[\begin{aligned}
\log p_i(x_i\mid \mu_i) &amp;= \mu_i \frac{x_i}{\sigma_i^2} - \frac{\mu_i^2}{2\sigma_i^2} - \frac{x_i^2}{2\sigma_i^2} - \frac{1}{2}\log(2\pi\sigma_i^2) \\
&amp;= \theta_i \tilde{x}_i - \sigma_i^{-2}\frac{\theta_i^2}{2} - 
\frac{\sigma_i^2 \tilde{x}_i^2}{2} - \frac{1}{2}\log(2\pi\sigma_i^2) \quad \bigg(\theta_i := \frac{\mu_i}{\sigma_i^2},\quad  \tilde{x}_i=\frac{x_i}{\sigma_i^2}\bigg),
\end{aligned}\]</p><p>we can infer the following:</p><ul><li>natural parameter: <span>$\displaystyle \theta = \frac{\mu}{\sigma^2}$</span></li><li><span>$\displaystyle \psi(\theta) = \frac{\sigma^2}{2}\theta^2$</span></li><li>weight: <span>$\displaystyle w_i = \sigma_i^{-2}$</span></li><li>expectation parameter: <span>$\eta_i = \psi ^\prime (\theta_i) = \sigma^2 \theta = \mu_i$</span></li></ul><p>Suppose we have <span>$n$</span> observations <span>$X_i \sim \mathrm{N}(\mu_i,\sigma_i^2)$</span>. The functions  <code>iso_Normal</code> and <code>iso_Normal!</code> solve the corresponding problem. Their input and output are as follows.</p><p>Input </p><ul><li><span>$x = (x_1,\dots,x_n)$</span></li><li><span>$\mathrm{variance} = (\sigma_1^2,\dots,\sigma_n^2)$</span></li></ul><p>Output</p><ul><li><span>$\hat{\eta} = (\hat{\eta}_1,\dots,\hat{\eta}_n) = (\hat{\mu}_1,\dots,\hat{\mu}_n)$</span>, which is monotone</li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Normal" href="#IsoFuns.iso_Normal"><code>IsoFuns.iso_Normal</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Normal(x::Vector, variance::Vector) -&gt; y</code></pre><p>Same as <code>iso_Normal!</code>, but allocates an output vector <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L104-L108">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Normal!" href="#IsoFuns.iso_Normal!"><code>IsoFuns.iso_Normal!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Normal!(x::Vector, variance::Vector) -&gt; x</code></pre><p>Perform isotonic regression (Normal)</p><p><strong>Arguments</strong></p><ul><li><code>x</code>: input vector </li><li><code>variance</code> a vector consisting of variances, default to ones if not provided</li></ul><p><strong>Outputs</strong></p><ul><li><code>x</code>: output vector, which is monotone</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L87-L99">source</a></section></article><hr/><h3 id="Binomial"><a class="docs-heading-anchor" href="#Binomial">Binomial</a><a id="Binomial-1"></a><a class="docs-heading-anchor-permalink" href="#Binomial" title="Permalink"></a></h3><p>The probability mass function (PMF) of the <strong>Binomial Distribution</strong> with the number of trials <span>$N_i$</span> and the probability of success <span>$r_i$</span> in an individual trial is given by</p><p class="math-container">\[p_i(x_i\mid r_i) = \begin{pmatrix} N_i \\ x_i \end{pmatrix} r_i^{x_i} (1-r_i)^{N_i-x_i}.\]</p><p>Since</p><p class="math-container">\[\begin{aligned}
\log p_i(x_i\mid r_i) &amp;= \big( \log r_i - \log(1-r_i) \big) x_i + N_i \log (1-r_i) + \log \begin{pmatrix} N_i \\ x_i \end{pmatrix} \\
&amp;= \theta_i x_i - N_i \log(1+\mathrm{e}^\theta_i) + \log \begin{pmatrix} N_i \\ x_i \end{pmatrix},
\end{aligned}\]</p><p>we can infer the following:</p><ul><li>natural parameter: <span>$\displaystyle \theta_i = \log r_i - \log(1-r_i) \quad \bigg( r_i = \frac{\mathrm{e}^\theta_i}{1+\mathrm{e}^\theta_i} \bigg)$</span></li><li><span>$\displaystyle \psi(\theta_i) =  \log(1+\mathrm{e}^\theta_i)$</span></li><li>weight: <span>$\displaystyle w_i = N_i$</span></li><li>expectation parameter: <span>$\displaystyle \eta_i  = \psi ^\prime (\theta) =  \frac{\mathrm{e}^\theta_i}{1+\mathrm{e}^\theta_i} = r_i$</span></li></ul><p>Suppose we have <span>$n$</span> observations <span>$X_i \sim \mathrm{Bi}(N_i,r_i)$</span>. The functions  <code>iso_Binomial</code> and <code>iso_Binomial!</code> solve the corresponding problem. Their input and output are as follows.</p><p>Input </p><ul><li><span>$x = (x_1,\dots,x_n)$</span></li><li><span>$w = (N_1,\dots,N_2)$</span></li></ul><p>Output</p><ul><li><span>$\hat{\eta} = (\hat{\eta}_1,\dots,\hat{\eta}_n) = (\hat{r}_1,\dots,\hat{r}_n)$</span>, which is monotone</li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Binomial" href="#IsoFuns.iso_Binomial"><code>IsoFuns.iso_Binomial</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Binomial(success::Vector, trial::Vector) -&gt; x</code></pre><p>Same as <code>iso_Binomial!</code>, but allocates an output vector <code>x</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L127-L131">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Binomial!" href="#IsoFuns.iso_Binomial!"><code>IsoFuns.iso_Binomial!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Binomial!(success::Vector, trial::Vector) -&gt; success</code></pre><p>Perform isotonic regression (Binomial)</p><p><strong>Arguments</strong></p><ul><li><code>success</code>: input vector consisting of the number of success</li><li><code>trials</code>: a vector consisting of the number of trials</li></ul><p><strong>Outputs</strong></p><ul><li><code>success</code>: output vector, which is monotone</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L112-L124">source</a></section></article><hr/><h3 id="Poisson"><a class="docs-heading-anchor" href="#Poisson">Poisson</a><a id="Poisson-1"></a><a class="docs-heading-anchor-permalink" href="#Poisson" title="Permalink"></a></h3><p>The PMF of the <strong>Poisson Distribution</strong> with the average rate of occurrence <span>$\lambda$</span> is gicen by</p><p class="math-container">\[p(x_i\mid \lambda_i) = \frac{\lambda_i^{x_i} \mathrm{e}^{-\lambda_i}}{x_i!}.\]</p><p>Since</p><p class="math-container">\[\begin{aligned}
\log p(x_i\mid \lambda_i) &amp;= x_i \log \lambda_i-\lambda_i-\log x_i! \\
&amp;= \theta_i x_i-\mathrm{e}^\theta_i-\log x_i!,
\end{aligned}\]</p><p>we can infer the following:</p><ul><li>natural parameter: <span>$\displaystyle \theta_i = \log\lambda_i$</span></li><li><span>$\displaystyle \psi(\theta_i) = \mathrm{e}^\theta_i$</span></li><li>weight: <span>$\displaystyle w_i = 1$</span></li><li>expectation parameter: <span>$\displaystyle \eta_i  = \psi ^\prime (\theta_i) = \mathrm{e}^\theta_i = \lambda_i$</span></li></ul><p>Suppose we have <span>$n$</span> observations <span>$X_i \sim \mathrm{Po}(\lambda_i)$</span>. The functions  <code>iso_Poisson</code> and <code>iso_Poisson!</code> solve the corresponding problem. Their input and output are as follows.</p><p>Input </p><ul><li><span>$x = (x_1,\dots,x_n)$</span></li></ul><p>Output</p><ul><li><span>$\hat{\eta} = (\hat{\eta}_1,\dots,\hat{\eta}_n) = (\hat{\lambda}_1,\dots,\hat{\lambda}_n)$</span>, which is monotone</li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Poisson" href="#IsoFuns.iso_Poisson"><code>IsoFuns.iso_Poisson</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Poisson(x::Vector) -&gt; y</code></pre><p>Same as <code>iso_Poisson!</code>, but allocates an output vector <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L148-L152">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Poisson!" href="#IsoFuns.iso_Poisson!"><code>IsoFuns.iso_Poisson!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Poisson!(x::Vector) -&gt; x</code></pre><p>Perform isotonic regression (Poisson)</p><p><strong>Arguments</strong></p><ul><li><code>x</code>: input vector consisting of the number of events</li></ul><p><strong>Outputs</strong></p><ul><li><code>x</code>: output vector, which is monotone</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L134-L145">source</a></section></article><hr/><h3 id="Chisq"><a class="docs-heading-anchor" href="#Chisq">Chisq</a><a id="Chisq-1"></a><a class="docs-heading-anchor-permalink" href="#Chisq" title="Permalink"></a></h3><p>The PDF of the <strong>Chi Squared Distribution</strong> (typically written <span>$\chi^2$</span>) with <span>$d_i$</span> degrees of freedom and scale parameter <span>$s_i$</span> is given by</p><p class="math-container">\[p_i(x_i\mid s_i) = \frac{1}{\Gamma(d_i/2) (2s_i)^{d_i/2}} x^{d_i/2-1} \mathrm{e}^{-\frac{x_i}{2s_i}} .\]</p><p>Since </p><p class="math-container">\[\begin{aligned}
\log p_i(x_i\mid s_i) &amp;= -\frac{1}{2s_i} x_i - \frac{d_i}{2} \log (2s_i) + \bigg( \frac{d_i}{2}-1\bigg)x_i - \log \Gamma (d_i/2)  \\
&amp;= \theta_i x_i - \frac{d_i}{2} (-\log (-\theta_i)) + \bigg( \frac{d_i}{2}-1\bigg)x_i - \log \Gamma (d_i/2) ,
\end{aligned}\]</p><p>we can infer the following:</p><ul><li>natural parameter: <span>$\displaystyle \theta_i = -\frac{1}{2s_i}$</span></li><li><span>$\displaystyle \psi(\theta_i) = - \log (\theta_i)$</span></li><li>weight: <span>$\displaystyle w_i = \frac{d_i}{2}$</span></li><li>expectation parameter: <span>$\displaystyle \eta_i  = \psi ^\prime (\theta_i) = -\frac{1}{\theta_i} = 2s_i$</span></li></ul><p>Suppose we have <span>$n$</span> observations <span>$X_i \sim s_i \chi^2(d_i)$</span>. The functions  <code>iso_Chisq</code> and <code>iso_Chisq!</code> solve the corresponding problem. Their input and output are as follows.</p><p>Input </p><ul><li><span>$x = (x_1,\dots,x_n)$</span></li><li><span>$w = (d_1,\dots,d_2)$</span></li></ul><p>Output</p><ul><li><span>$\hat{\eta} = (\hat{\eta}_1,\dots,\hat{\eta}_n) = (2\hat{s}_1,\dots,2\hat{s}_n)$</span>, which is monotone</li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Chisq" href="#IsoFuns.iso_Chisq"><code>IsoFuns.iso_Chisq</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Chisq(x::Vector, d::Vector) -&gt; y</code></pre><p>Same as <code>iso_Chisq!</code>, but allocates an output vector <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L170-L174">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="IsoFuns.iso_Chisq!" href="#IsoFuns.iso_Chisq!"><code>IsoFuns.iso_Chisq!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">iso_Chisq!(x::Vector, d::Vector) -&gt; x</code></pre><p>Perform isotonic regression (Chisq)</p><p><strong>Arguments</strong></p><ul><li><code>x</code>: input vector </li><li><code>d</code>: a vector consisting of the degrees of freedom</li></ul><p><strong>Outputs</strong></p><ul><li><code>x</code>: output vector, which is monotone</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/yutomiyatake/IsoFuns.jl/blob/c69e69155832825c2a6ff11af254c6d8d3576653/src/iso.jl#L155-L167">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../neariso/">Nearly isotonic regression »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Saturday 9 December 2023 04:37">Saturday 9 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
